{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy Customers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Description:\n",
    "\n",
    "* Y = target attribute (Y) with values indicating 0 (unhappy) and 1 (happy) customers\n",
    "* X1 = my order was delivered on time\n",
    "* X2 = contents of my order was as I expected\n",
    "* X3 = I ordered everything I wanted to order\n",
    "* X4 = I paid a good price for my order\n",
    "* X5 = I am satisfied with my courier\n",
    "* X6 = the app makes ordering easy for me\n",
    "\n",
    "Attributes X1 to X6 indicate the responses for each question and have values from 1 to 5 where the smaller number indicates less and the higher number indicates more towards the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal : Predict if a customer is happy or not based on the answers they give to questions asked.\n",
    "\n",
    "Success Metrics : Reach 73% accuracy score or above, or convince us why your solution is superior. We are definitely interested in every solution and insight you can provide us.\n",
    "\n",
    "Try to submit your working solution as soon as possible. The sooner the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Y  X1  X2  X3  X4  X5  X6\n",
       "102  0   5   2   3   3   3   5\n",
       "40   0   5   2   3   3   3   3\n",
       "48   1   5   2   5   5   5   3\n",
       "16   0   5   3   4   5   4   5\n",
       "54   1   4   3   2   4   3   4\n",
       "42   0   5   2   3   3   4   5\n",
       "69   1   5   4   5   5   5   5\n",
       "75   0   3   2   3   3   4   4\n",
       "74   1   5   2   5   5   5   5\n",
       "84   0   4   3   4   4   2   4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load the data and take a look at it \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ACME-HappinessSurvey2020.csv\")\n",
    "\n",
    "# Allows us to see n numer of random samples from the dataframe\n",
    "df.sample(10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 7 columns):\n",
      "Y     126 non-null int64\n",
      "X1    126 non-null int64\n",
      "X2    126 non-null int64\n",
      "X3    126 non-null int64\n",
      "X4    126 non-null int64\n",
      "X5    126 non-null int64\n",
      "X6    126 non-null int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 7.0 KB\n"
     ]
    }
   ],
   "source": [
    "# What are our column data types?\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y     0\n",
       "X1    0\n",
       "X2    0\n",
       "X3    0\n",
       "X4    0\n",
       "X5    0\n",
       "X6    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we have any null values?\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Y</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.499714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X2</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.531746</td>\n",
       "      <td>1.114892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X3</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.309524</td>\n",
       "      <td>1.023440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X4</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.746032</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.650794</td>\n",
       "      <td>1.147641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X6</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4.253968</td>\n",
       "      <td>0.809311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count      mean       std  min  25%  50%  75%  max\n",
       "Y   126.0  0.547619  0.499714  0.0  0.0  1.0  1.0  1.0\n",
       "X1  126.0  4.333333  0.800000  1.0  4.0  5.0  5.0  5.0\n",
       "X2  126.0  2.531746  1.114892  1.0  2.0  3.0  3.0  5.0\n",
       "X3  126.0  3.309524  1.023440  1.0  3.0  3.0  4.0  5.0\n",
       "X4  126.0  3.746032  0.875776  1.0  3.0  4.0  4.0  5.0\n",
       "X5  126.0  3.650794  1.147641  1.0  3.0  4.0  4.0  5.0\n",
       "X6  126.0  4.253968  0.809311  1.0  4.0  4.0  5.0  5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive stats\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Y</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280160</td>\n",
       "      <td>-0.024274</td>\n",
       "      <td>0.150838</td>\n",
       "      <td>0.064415</td>\n",
       "      <td>0.224522</td>\n",
       "      <td>0.167669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X1</td>\n",
       "      <td>0.280160</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.411873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X2</td>\n",
       "      <td>-0.024274</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>-0.062205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X3</td>\n",
       "      <td>0.150838</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.203750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X4</td>\n",
       "      <td>0.064415</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>0.215888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X5</td>\n",
       "      <td>0.224522</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X6</td>\n",
       "      <td>0.167669</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Y        X1        X2        X3        X4        X5        X6\n",
       "Y   1.000000  0.280160 -0.024274  0.150838  0.064415  0.224522  0.167669\n",
       "X1  0.280160  1.000000  0.059797  0.283358  0.087541  0.432772  0.411873\n",
       "X2 -0.024274  0.059797  1.000000  0.184129  0.114838  0.039996 -0.062205\n",
       "X3  0.150838  0.283358  0.184129  1.000000  0.302618  0.358397  0.203750\n",
       "X4  0.064415  0.087541  0.114838  0.302618  1.000000  0.293115  0.215888\n",
       "X5  0.224522  0.432772  0.039996  0.358397  0.293115  1.000000  0.320195\n",
       "X6  0.167669  0.411873 -0.062205  0.203750  0.215888  0.320195  1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation, do we have linear relaiton for our questions?\n",
    "# Ex: If one of them is low, are there any others following it?\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y     1.000000\n",
       "X1    0.280160\n",
       "X5    0.224522\n",
       "X6    0.167669\n",
       "X3    0.150838\n",
       "X4    0.064415\n",
       "X2   -0.024274\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation with happiness\n",
    "\n",
    "df.corr()[\"Y\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    69\n",
       "0    57\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How is happy-unhappy classes are distributed, do we need balancing classes?\n",
    "\n",
    "df[\"Y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (100, 6)\n",
      "Number transactions y_train dataset:  (100,)\n",
      "Number transactions X_test dataset:  (26, 6)\n",
      "Number transactions y_test dataset:  (26,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset to train and test datasets\n",
    "\n",
    "X = df.iloc[:,[1,2,3,4,5,6]]\n",
    "y = df[\"Y\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log = LogisticRegression().fit(X_train,y_train)\n",
    "preds = model_log.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of happy customers : 19\n",
      "Number of unhappy customers : 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of happy customers : {}\".format(preds.sum()))\n",
    "print(\"Number of unhappy customers : {}\".format(len(preds) - preds.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is : %61.53846153846154\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score of the model\n",
    "print(\"Accuracy of the model is : %{}\".format(accuracy_score(y_test, preds)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_dt = DecisionTreeClassifier()\n",
    "model_dt.fit(X_train,y_train)\n",
    "preds_dt = model_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of happy customers : 13\n",
      "Number of unhappy customers : 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of happy customers : {}\".format(preds_dt.sum()))\n",
    "print(\"Number of unhappy customers : {}\".format(len(preds_dt) - preds_dt.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is : %46.15384615384615\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score of the model\n",
    "print(\"Accuracy of the model is : %{}\".format(accuracy_score(y_test, preds_dt)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf= RandomForestClassifier(random_state=1)\n",
    "model_rf.fit(X_train,y_train)\n",
    "preds_rf=model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of happy customers : 17\n",
      "Number of unhappy customers : 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of happy customers : {}\".format(preds_rf.sum()))\n",
    "print(\"Number of unhappy customers : {}\".format(len(preds_rf) - preds_rf.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is : %53.84615384615385\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score of the model\n",
    "print(\"Accuracy of the model is : %{}\".format(accuracy_score(y_test, preds_rf)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch to optimize models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Semanur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "\n",
    "grid_log=GridSearchCV(model_log,grid)\n",
    "grid_log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.01, 'penalty': 'l2'}\n",
      "accuracy : 0.56\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",grid_log.best_params_)\n",
    "print(\"accuracy :\",grid_log.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Best parameters for Grid search is:\n",
      "{'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
      "==========================================\n",
      "0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "grid_search1_params = {\n",
    "    'max_depth': [3,4,5,6,7],\n",
    "    'min_samples_leaf': [3,4,5],\n",
    "    'min_samples_split': [3,4,5]\n",
    "             }\n",
    "\n",
    "grid_search1 = GridSearchCV(model_dt, grid_search1_params, cv=5, n_jobs=-2)\n",
    "grid_search1.fit(X_train, y_train)\n",
    "pred_grid=grid_search1.predict(X_test)\n",
    "\n",
    "print(\"==========================================\")\n",
    "print(\"Best parameters for Grid search is:\")\n",
    "print(grid_search1.best_params_)\n",
    "print(\"==========================================\")\n",
    "print(accuracy_score(y_test,pred_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  35 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-2)]: Done 156 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-2)]: Done 359 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-2)]: Done 642 tasks      | elapsed:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Best parameters for Grid search is:\n",
      "{'max_leaf_nodes': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "==========================================\n",
      "0.6153846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done 750 out of 750 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "grid_search2_params = {\n",
    "    'max_leaf_nodes': [5,6,7,8,9,10],\n",
    "    'min_samples_split': [2,3,4,6,8],\n",
    "     \"n_estimators\" : [100, 200, 300, 400, 500]\n",
    "             }\n",
    "\n",
    "grid_search2 = GridSearchCV(model_rf, grid_search2_params, cv=5, verbose=2, n_jobs=-2)\n",
    "grid_search2.fit(X_train, y_train)\n",
    "pred_grid2=grid_search2.predict(X_test)\n",
    "\n",
    "print(\"==========================================\")\n",
    "print(\"Best parameters for Grid search is:\")\n",
    "print(grid_search2.best_params_)\n",
    "print(\"==========================================\")\n",
    "print(accuracy_score(y_test,pred_grid2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model_LGBM = LGBMClassifier().fit(X_train,y_train)\n",
    "pred_LGBM = model_LGBM.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,pred_LGBM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Best parameters for Grid search is:\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 500, 'num_leaves': 3}\n",
      "==========================================\n",
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "params_LGBM = {\"learning_rate\" : [0.001, 0.01, 0.1],\n",
    "          \"n_estimators\" : [100, 200, 300, 400, 500],\n",
    "          \"max_depth\" : [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "              \"num_leaves\":[2,3,4,5]}\n",
    "\n",
    "grid_search = GridSearchCV(model_LGBM, params_LGBM, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "pred_grid=grid_search.predict(X_test)\n",
    "\n",
    "print(\"==========================================\")\n",
    "print(\"Best parameters for Grid search is:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"==========================================\")\n",
    "print(accuracy_score(y_test,pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying different grid search models, we couldn't beat our best score, which is approximately 0.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE (Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LGBMClassifier())"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(model_LGBM,step=1)\n",
    "rfe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected True, Rank: 1.000\n",
      "Column: 1, Selected True, Rank: 1.000\n",
      "Column: 2, Selected False, Rank: 3.000\n",
      "Column: 3, Selected True, Rank: 1.000\n",
      "Column: 4, Selected False, Rank: 4.000\n",
      "Column: 5, Selected False, Rank: 2.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_train.shape[1]):\n",
    "    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of selected features: 3\n"
     ]
    }
   ],
   "source": [
    "sum=rfe.ranking_[rfe.ranking_==1].sum()\n",
    "\n",
    "print(\"Total number of selected features: %d\" % (sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7307692307692307\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,rfe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "rfe2 = RFE(model_log,step=3)\n",
    "rfe2.fit(X_train,y_train)\n",
    "print(accuracy_score(y_test,rfe2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to get an accuracy just above 0.73 after RFE. \n",
    "\n",
    "Comment: I am not sure if we can apply any feature elimination techniques to a survey dataset since every column represents questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In relatively small datasets, sometimes rather than choosing more advanced models to improve accuracy, it is better to tackle some other algorithms and select the one that fits best. Applying regression to a classification model is one of them. Here I tried to apply regression and obtained some continuous predictions. Later on I decided on some key value, 0.65 for this case, and set the values aboue this as 1. The ones below as 0. 0.65 is an arbitrary number given by trying different values starting from 0.5 (I am trying this method for the first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61416641, 0.65338591, 0.46174141, 0.48135541, 0.72015349,\n",
       "       0.33488129, 0.41986033, 0.67729651, 0.65907771, 0.521422  ,\n",
       "       0.37288508, 0.53626817, 0.50872744, 0.7988093 , 0.63335147,\n",
       "       0.58636659, 0.59188968, 0.52711494, 0.66684423, 0.679111  ,\n",
       "       0.50344302, 0.75528241, 0.36900778, 0.72263674, 0.68298945,\n",
       "       0.64027206])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear = LinearRegression().fit(X_train,y_train)\n",
    "pred_linear = model_linear.predict(X_test)\n",
    "pred_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_linear = [0 if i<0.65 else 1 for i in pred_linear ]\n",
    "corr_lin = pd.Series(corrected_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6538461538461539"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,corr_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use a \"Linear Explainer\" since Logistic regression is a Linear Model\n",
    "explainer = shap.LinearExplainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "pd.DataFrame(shap_values, columns=X_test.columns).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Expected Value:', explainer.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=pd.DataFrame(shap_values, columns=X_test.columns)\n",
    "a.loc[0,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test data (actual observation): {}\".format(y_test.iloc[1]))\n",
    "print(\"Model's prediction: {}\".format(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
